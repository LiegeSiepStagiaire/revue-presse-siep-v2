
import streamlit as st
import feedparser
from datetime import datetime
import pandas as pd

st.set_page_config(page_title="Revue de presse SIEP (RSS)", page_icon="üì∞", layout="wide")

rubriques = {'Travail et Insertion Socio-Professionnelle': ['emploi', 'recherche d‚Äôemploi', 'l√©gislation du travail', 'contrat', 'job √©tudiant', 'insertion socio-professionnelle', 'CISP', 'ann√©e citoyenne', 'volontariat', 'r√©daction de CV'], 'Enseignement de plein exercice : secondaire et sup√©rieur': ['√©tudes', 'enseignement secondaire', 'enseignement sup√©rieur', 'enseignement qualifiant', 'd√©cret', 'structure scolaire', 'organisation des √©tudes', '√©tablissement scolaire', 'droit scolaire', 'exclusion scolaire', 'recours scolaire', 'acc√®s aux √©tudes', 'co√ªt des √©tudes', 'bourse d‚Äô√©tude', 'pr√™t d‚Äô√©tude', 'CPMS', '√©cole de devoirs', 'rem√©diation', 'm√©thode de travail', 'aide √† la r√©ussite', 'tutorat', 'DASPA', 'certification', 'choix d‚Äô√©tudes', 'ann√©e pr√©paratoire', 'journ√©e portes ouvertes', 'passerelle', 'valorisation des acquis (VAE)'], 'Formation': ['formation en alternance', 'CEFA', 'IFAPME', 'EFP', 'jury', 'enseignement √† distance', 'horaire r√©duit', 'alphab√©tisation', 'promotion sociale', 'formation demandeur d‚Äôemploi', 'FOREM', 'ACTIRIS', 'centre de comp√©tence', 'validation des comp√©tences'], 'Protection sociale / aide aux personnes': ['ch√¥mage', 'mutuelle', 'aide sociale', 'revenu d‚Äôint√©gration sociale (RIS)', 'allocations familiales', 'financement des √©tudes', 'aide √† la jeunesse'], 'Vie familiale et affective': ['sexualit√©', 'planning familial', '√©galit√© des genres', 'animation GDBD', 'charte √©galit√©'], 'Qualit√© de vie': ['sant√©', 'consommation', 'harc√®lement', 'sensibilisation', 'logement interg√©n√©rationnel', 'kot √©tudiant', 'contrat de bail', 'transport'], 'Loisirs / vacances': ['sport', 'stage vacances', 'formation animateur', 'centre d‚Äôh√©bergement', 'centre de rencontre'], 'International': ['projet international', 's√©jour linguistique', 'stage √† l‚Äô√©tranger', 'apprendre les langues', 'bourse internationale', 'test de langue', 'niveau CECRL', 'mobilit√© europ√©enne'], '√ätre acteur dans la soci√©t√© / Institutions et justice': ['citoyennet√©', 'droits', 'devoirs', 'engagement', 'implication politique', 'd√©mocratie', 'droit √† l‚Äôimage', 'r√©seaux sociaux', 'nationalit√©', 'institutions belges', 'institutions europ√©ennes', 'droits humains', 'partis politiques', 'participation des jeunes', 'mouvements philosophiques', 'police', 'justice', 'groupe de pression'], 'Les M√©tiers': ['orientation m√©tier', 'projet de vie', 'connaissance de soi', 'information m√©tier', 'exploration', 'rencontre professionnelle']}
rss_feeds = {'RTBF': 'https://www.rtbf.be/rss', 'Le Soir': 'https://www.lesoir.be/rss/lesoir.xml', 'La Libre': 'https://www.lalibre.be/rss/section/actu.xml', "L'√âcho": 'https://www.lecho.be/rss/algemeen.xml', 'Sudinfo': 'https://www.sudinfo.be/rss', 'DH': 'https://www.dhnet.be/rss/dh.xml', 'BX1': 'https://bx1.be/feed/', 'Le Vif': 'https://www.levif.be/rss.xml', 'Actiris': 'https://www.actiris.brussels/fr/rss/news/', 'Le Forem': 'https://www.leforem.be/RSS/actualites.html'}

st.title("Revue de presse üìö - SIEP Li√®ge (Flux directs)")

rubrique = st.selectbox("Choisissez une rubrique :", list(rubriques.keys()))
custom_keyword = st.text_input("üîé (Optionnel) Ajouter un mot-cl√© personnalis√© pour affiner la recherche :")
start_date = st.date_input("üìÖ Date de d√©but", datetime.today())
end_date = st.date_input("üìÖ Date de fin", datetime.today())

if 'article_history' not in st.session_state:
    st.session_state.article_history = []
    st.session_state.deleted_stack = []

def article_date_valid(published, start, end):
    try:
        article_date = datetime(*published[:6])
        return start <= article_date.date() <= end
    except:
        return True

if st.button("üîç Rechercher"):
    total_articles = []
    mots_cl√©s = [custom_keyword] if custom_keyword else rubriques[rubrique]
    mots_capt√©s = set()

    for source, url in rss_feeds.items():
        feed = feedparser.parse(url)
        for entry in feed.entries:
            title = entry.title
            summary = entry.get("summary", "")
            link = entry.link
            date = entry.get("published_parsed") or entry.get("updated_parsed")
            if not article_date_valid(date, start_date, end_date):
                continue
            for mot in mots_cl√©s:
                if mot.lower() in title.lower() or mot.lower() in summary.lower():
                    mots_capt√©s.add(mot)
                    formatted_date = datetime(*date[:6]).strftime('%d/%m/%Y %H:%M') if date else ""
                    total_articles.append({
                        "title": title,
                        "summary": summary,
                        "link": link,
                        "source": source,
                        "date": formatted_date,
                        "mot_cl√©": mot
                    })
                    break

    # Supprimer les doublons
    seen = set()
    filtered_articles = []
    for a in total_articles:
        key = (a['title'], a['link'])
        if key not in seen:
            seen.add(key)
            filtered_articles.append(a)

    st.session_state.article_history = filtered_articles
    st.session_state.deleted_stack = []

    if mots_capt√©s:
        st.success("Mots-cl√©s ayant donn√© des r√©sultats : " + ", ".join(sorted(mots_capt√©s)))
    else:
        st.info("Aucun mot-cl√© n'a donn√© de r√©sultat pour cette p√©riode.")

if st.session_state.article_history:
    search_filter = st.text_input("üîç Filtrer les r√©sultats par mot dans le titre :", "")
    for i, article in enumerate(st.session_state.article_history):
        if search_filter.lower() in article['title'].lower():
            cols = st.columns([5, 1, 1])
            cols[0].markdown(f"**{{article['title']}}**  \n_{{article['source']}} - {{article['date']}}_  \n[Lire l'article]({{article['link']}})"){article['source']} - {article['date']}_  
[Lire l'article]({article['link']})")
            if cols[1].button("üóëÔ∏è Supprimer", key=f"delete_{i}"):
                st.session_state.deleted_stack.append(article)
                st.session_state.article_history.pop(i)
                st.rerun()

    col1, col2, col3 = st.columns(3)
    if col1.button("‚Ü©Ô∏è Revenir en arri√®re", disabled=not st.session_state.deleted_stack):
        last_deleted = st.session_state.deleted_stack.pop()
        st.session_state.article_history.append(last_deleted)
        st.rerun()

    df = pd.DataFrame(st.session_state.article_history)
    csv = df.to_csv(index=False).encode('utf-8')
    col3.download_button("‚¨áÔ∏è Exporter en CSV", data=csv, file_name="revue_presse_siep.csv", mime="text/csv")
else:
    st.info("Aucun article trouv√© pour les crit√®res s√©lectionn√©s.")
