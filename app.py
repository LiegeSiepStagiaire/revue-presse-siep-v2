
import streamlit as st
import feedparser
from datetime import datetime, timedelta
import pandas as pd
import base64

# Configuration
st.set_page_config(page_title="Revue de presse SIEP", page_icon="üì∞", layout="wide")

# Logo et titre
col1, col2 = st.columns([9, 1])
with col1:
    st.title("Revue de presse üìö - SIEP Li√®ge")
with col2:
    with open("/mnt/data/Mode_emploi_SIEP_complet.pdf", "rb") as f:
        st.download_button("üìò Mode d'emploi + rubriques", f, file_name="Mode_emploi_SIEP_complet.pdf")

# Donn√©es
rubriques = {
    "Travail et Insertion Socio-Professionnelle": [
        "emploi", "recherche d‚Äôemploi", "l√©gislation du travail", "contrat",
        "job √©tudiant", "insertion socio-professionnelle", "CISP",
        "ann√©e citoyenne", "volontariat", "r√©daction de CV"
    ],
    "Enseignement de plein exercice": [
        "√©tudes", "enseignement secondaire", "enseignement sup√©rieur", "enseignement qualifiant",
        "d√©cret", "structure scolaire", "organisation des √©tudes", "√©tablissement scolaire",
        "droit scolaire", "exclusion scolaire", "recours scolaire", "acc√®s aux √©tudes",
        "co√ªt des √©tudes", "bourse d‚Äô√©tude", "pr√™t d‚Äô√©tude", "CPMS", "√©cole de devoirs",
        "rem√©diation", "m√©thode de travail", "aide √† la r√©ussite", "tutorat", "DASPA",
        "certification", "choix d‚Äô√©tudes", "ann√©e pr√©paratoire", "journ√©e portes ouvertes",
        "passerelle", "valorisation des acquis (VAE)"
    ]
}

sources_fiables = [
    "rtbf.be", "lesoir.be", "lalibre.be", "lecho.be", "sudpresse.be",
    "forem.be", "actiris.be", "siep.be", "enseignement.be",
    "enseignement.catholique.be", "cfwb.be", "socialsecurity.be",
    "emploi.belgique.be"
]

# Fonctions
def create_rss_url(keyword, start_date, end_date):
    base_url = "https://news.google.com/rss/search?"
    query = f"q={keyword.replace(' ', '+')}+after:{start_date}+before:{end_date}"
    params = "&hl=fr&gl=BE&ceid=BE:fr"
    return base_url + query + params

def get_articles(rss_url, additional_sources):
    feed = feedparser.parse(rss_url)
    articles = []
    for entry in feed.entries:
        link = entry.link
        if any(source in link for source in sources_fiables + additional_sources):
            articles.append({
                "title": entry.title,
                "link": link,
                "date": entry.published if 'published' in entry else "",
                "source": link.split('/')[2]
            })
    return articles

# UI
rubrique = st.selectbox("Rubrique", list(rubriques.keys()))
col1, col2 = st.columns(2)
with col1:
    start_date = st.date_input("Date de d√©but", datetime.today() - timedelta(days=30))
with col2:
    end_date = st.date_input("Date de fin", datetime.today())

custom_sources_input = st.text_input("Ajouter des sites web suppl√©mentaires √† consulter (ex: https://mon-site.be), s√©par√©s par des virgules :", "")
custom_sources = [url.strip().replace("https://", "").replace("http://", "").strip("/") for url in custom_sources_input.split(",") if url.strip()]
custom_keyword = st.text_input("Rechercher un mot-cl√© personnalis√© (optionnel) :")

if st.button("üîç Rechercher"):
    start_str = start_date.strftime('%Y-%m-%d')
    end_str = end_date.strftime('%Y-%m-%d')
    st.subheader(f"R√©sultats pour la rubrique '{rubrique}' entre {start_str} et {end_str}")

    total_articles = []
    keywords = [custom_keyword] if custom_keyword else rubriques[rubrique]

    for keyword in keywords:
        url = create_rss_url(keyword, start_str, end_str)
        total_articles.extend(get_articles(url, custom_sources))

    seen = set()
    filtered_articles = []
    for article in total_articles:
        key = (article['title'], article['link'])
        if key not in seen:
            seen.add(key)
            filtered_articles.append(article)

    if filtered_articles:
        for article in filtered_articles:
            st.markdown(
                f"**{article['title']}**  
"
                f"_{article['source']} ‚Äì {article['date']}_  
"
                f"[Lire l'article]({article['link']})"
            )
            st.markdown("---")
    else:
        st.info("Aucun article pertinent trouv√© pour cette rubrique et cette p√©riode.")
