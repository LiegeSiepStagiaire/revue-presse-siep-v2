
import streamlit as st
import feedparser
from datetime import datetime, timedelta
import pandas as pd

st.set_page_config(page_title="Revue de presse SIEP", page_icon="üì∞", layout="wide")

rubriques = {
    "Travail et Insertion Socio-Professionnelle": [
        "emploi", "recherche d‚Äôemploi", "l√©gislation du travail", "contrat",
        "job √©tudiant", "insertion socio-professionnelle", "CISP",
        "ann√©e citoyenne", "volontariat", "r√©daction de CV"
    ],
    "Enseignement de plein exercice : secondaire et sup√©rieur": [
        "√©tudes", "enseignement secondaire", "enseignement sup√©rieur", "enseignement qualifiant", "d√©cret",
        "structure scolaire", "organisation des √©tudes", "√©tablissement scolaire", "droit scolaire",
        "exclusion scolaire", "recours scolaire", "acc√®s aux √©tudes", "co√ªt des √©tudes", "bourse d‚Äô√©tude",
        "pr√™t d‚Äô√©tude", "CPMS", "√©cole de devoirs", "rem√©diation", "m√©thode de travail", "aide √† la r√©ussite",
        "tutorat", "DASPA", "certification", "choix d‚Äô√©tudes", "ann√©e pr√©paratoire", "journ√©e portes ouvertes",
        "passerelle", "valorisation des acquis (VAE)"
    ],
    "Formation": [
        "formation en alternance", "CEFA", "IFAPME", "EFP", "jury", "enseignement √† distance",
        "horaire r√©duit", "alphab√©tisation", "promotion sociale", "formation demandeur d‚Äôemploi",
        "FOREM", "ACTIRIS", "centre de comp√©tence", "validation des comp√©tences"
    ],
    "Protection sociale / aide aux personnes": [
        "ch√¥mage", "mutuelle", "aide sociale", "revenu d‚Äôint√©gration sociale (RIS)",
        "allocations familiales", "financement des √©tudes", "aide √† la jeunesse"
    ],
    "Vie familiale et affective": [
        "sexualit√©", "planning familial", "√©galit√© des genres", "animation GDBD", "charte √©galit√©"
    ],
    "Qualit√© de vie": [
        "sant√©", "consommation", "harc√®lement", "sensibilisation", "logement interg√©n√©rationnel",
        "kot √©tudiant", "contrat de bail", "transport"
    ],
    "Loisirs / vacances": [
        "sport", "stage vacances", "formation animateur", "centre d‚Äôh√©bergement", "centre de rencontre"
    ],
    "International": [
        "projet international", "s√©jour linguistique", "stage √† l‚Äô√©tranger", "apprendre les langues",
        "bourse internationale", "test de langue", "niveau CECRL", "mobilit√© europ√©enne"
    ],
    "√ätre acteur dans la soci√©t√© / Institutions et justice": [
        "citoyennet√©", "droits", "devoirs", "engagement", "implication politique", "d√©mocratie",
        "droit √† l‚Äôimage", "r√©seaux sociaux", "nationalit√©", "institutions belges", "institutions europ√©ennes",
        "droits humains", "partis politiques", "participation des jeunes", "mouvements philosophiques",
        "police", "justice", "groupe de pression"
    ],
    "Les M√©tiers": [
        "orientation m√©tier", "projet de vie", "connaissance de soi", "information m√©tier",
        "exploration", "rencontre professionnelle"
    ]
}

sources_fiables = [
    "rtbf.be", "lesoir.be", "lalibre.be", "lecho.be", "sudpresse.be",
    "forem.be", "actiris.be", "siep.be", "enseignement.be",
    "enseignement.catholique.be", "cfwb.be", "socialsecurity.be",
    "emploi.belgique.be", "bx1.be", "guide-social.be", "dhnet.be", "jobat.be",
    "lanouvellegazette.be", "references.lesoir.be", "emploi.wallonie.be",
    "enseignement.cfwb.be", "monorientation.be", "volontariat.be",
    "jeminforme.be", "citedesmetiers.be", "onem.be", "solidaris.be"
]

def create_rss_url(keyword, start_date, end_date):
    base_url = "https://news.google.com/rss/search?"
    query = f"q={keyword.replace(' ', '+')}+after:{start_date}+before:{end_date}"
    params = "&hl=fr&gl=BE&ceid=BE:fr"
    return base_url + query + params

def get_articles(rss_url, sources, accept_all=False):
    feed = feedparser.parse(rss_url)
    articles = []
    for entry in feed.entries:
        link = entry.link
        if accept_all or any(source in link for source in sources):
            articles.append({
                "title": entry.title,
                "link": link,
                "date": entry.published if 'published' in entry else ""
            })
    return articles

st.title("Revue de presse üìö - SIEP Li√®ge")

rubrique = st.selectbox("Rubrique", list(rubriques.keys()))

colA, colB = st.columns(2)
start_date = colA.date_input("üìÖ Date de d√©but", datetime.today() - timedelta(days=30))
end_date = colB.date_input("üìÖ Date de fin", datetime.today())

custom_sources_input = st.text_input("üîó Ajouter des sites web suppl√©mentaires (ex: https://mon-site.be), s√©par√©s par des virgules :")
custom_sources = [url.strip().replace("https://", "").replace("http://", "").strip("/") for url in custom_sources_input.split(",") if url.strip()]
accept_all = st.checkbox("üëÄ Voir aussi les sources non v√©rifi√©es")

if 'article_history' not in st.session_state:
    st.session_state.article_history = []
    st.session_state.deleted_stack = []

if st.button("üîç Rechercher"):
    total_articles = []
    for keyword in rubriques[rubrique]:
        url = create_rss_url(keyword, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))
        articles = get_articles(url, sources_fiables + custom_sources, accept_all)
        total_articles.extend(articles)

    seen = set()
    filtered_articles = []
    for article in total_articles:
        key = (article['title'], article['link'])
        if key not in seen:
            seen.add(key)
            filtered_articles.append(article)

    st.session_state.article_history = filtered_articles
    st.session_state.deleted_stack = []

if st.session_state.article_history or st.session_state.article_history == []:
    search_filter = st.text_input("üîç Filtrer les articles par mot-cl√© dans le titre :", "")

    for i, article in enumerate(st.session_state.article_history):
        if search_filter.lower() in article['title'].lower():
            cols = st.columns([5, 1, 1])
            cols[0].markdown(f"**{article['title']}**  \n_{article['date']}_  \nüîó [Lire l'article]({article['link']})")
            if cols[1].button("üóëÔ∏è Supprimer", key=f"delete_{i}"):
                st.session_state.deleted_stack.append(article)
                st.session_state.article_history.pop(i)
                st.experimental_rerun()

    col1, col2, col3 = st.columns(3)
    if col1.button("‚Ü©Ô∏è Revenir en arri√®re", disabled=not st.session_state.deleted_stack):
        last_deleted = st.session_state.deleted_stack.pop()
        st.session_state.article_history.append(last_deleted)
        st.experimental_rerun()

    df_export = pd.DataFrame(st.session_state.article_history)
    csv = df_export.to_csv(index=False).encode('utf-8')
    col3.download_button("‚¨áÔ∏è Exporter en CSV", data=csv, file_name="revue_presse_siep.csv", mime="text/csv")

if not st.session_state.article_history:
    st.warning("Aucun article pertinent trouv√© pour cette rubrique et cette p√©riode.")
